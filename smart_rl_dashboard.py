#!/usr/bin/env python3
"""
Smart RL Dashboard - Sophisticated Auto-RL Management Interface
"""

import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
from typing import Dict, List, Any
import asyncio
import sys
import os

# Add paths
sys.path.append('.')
from auto_rl_system import auto_rl_manager, AutoRLAnalyzer, RLDecision
from enhanced_production_api import enhanced_service, RL_ENABLED

class SmartRLDashboard:
    def __init__(self):
        self.analyzer = AutoRLAnalyzer()
        self.rl_sessions = []
        self.performance_data = []
        
    def create_rl_intelligence_panel(self):
        """Create intelligent RL management panel"""
        
        st.header("ğŸ§  Intelligent RL Training System")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Auto-RL Status", "ğŸŸ¢ Active", "Smart decisions enabled")
        
        with col2:
            total_sessions = len(self.rl_sessions)
            st.metric("RL Sessions Today", total_sessions, f"+{total_sessions} automated")
        
        with col3:
            if auto_rl_manager:
                active_agents = auto_rl_manager.get_rl_stats().get('active_rl_agents', 0)
                st.metric("Agents with RL", active_agents, "Learning actively")
            else:
                st.metric("Agents with RL", 0, "System offline")
        
        with col4:
            efficiency = 85.7  # Mock efficiency score
            st.metric("RL Efficiency", f"{efficiency}%", "+12% this week")
    
    def create_task_analyzer(self):
        """Create real-time task analysis interface"""
        
        st.subheader("ğŸ¯ Real-Time Task Analysis")
        
        # Task input
        task_input = st.text_area(
            "Enter a task to analyze RL potential:",
            placeholder="e.g., Optimize the database queries for the user analytics system",
            height=100
        )
        
        # Agent selection
        agent_options = [
            "full_stack_developer", "data_scientist", "devops_engineer", 
            "system_architect", "security_expert", "ui_ux_designer"
        ]
        selected_agent = st.selectbox("Select Agent:", agent_options)
        
        if st.button("ğŸ” Analyze Task", type="primary"):
            if task_input:
                # Analyze task
                recommendation = self.analyzer.analyze_task(task_input, selected_agent)
                
                # Create analysis visualization
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    # RL Decision Chart
                    decision_colors = {
                        "skip": "#ff4444",
                        "light": "#ffaa44", 
                        "standard": "#44aaff",
                        "intensive": "#44ff44"
                    }
                    
                    fig = go.Figure(go.Indicator(
                        mode = "gauge+number+delta",
                        value = recommendation.confidence * 100,
                        domain = {'x': [0, 1], 'y': [0, 1]},
                        title = {'text': f"RL Confidence: {recommendation.decision.value.upper()}"},
                        delta = {'reference': 50},
                        gauge = {
                            'axis': {'range': [None, 100]},
                            'bar': {'color': decision_colors.get(recommendation.decision.value, "#888888")},
                            'steps': [
                                {'range': [0, 25], 'color': "lightgray"},
                                {'range': [25, 50], 'color': "gray"},
                                {'range': [50, 75], 'color': "lightblue"},
                                {'range': [75, 100], 'color': "lightgreen"}
                            ],
                            'threshold': {
                                'line': {'color': "red", 'width': 4},
                                'thickness': 0.75,
                                'value': 90
                            }
                        }
                    ))
                    
                    fig.update_layout(height=300)
                    st.plotly_chart(fig, use_container_width=True)
                
                with col2:
                    # Decision details
                    st.markdown("### ğŸ“Š Analysis Results")
                    
                    decision_emoji = {
                        "skip": "âšª",
                        "light": "ğŸŸ¡", 
                        "standard": "ğŸ”µ",
                        "intensive": "ğŸŸ¢"
                    }
                    
                    st.markdown(f"""
                    **Decision:** {decision_emoji.get(recommendation.decision.value)} {recommendation.decision.value.title()}
                    
                    **Algorithm:** {recommendation.algorithm or 'None'}
                    
                    **Epochs:** {recommendation.epochs}
                    
                    **Confidence:** {recommendation.confidence:.1%}
                    """)
                
                # Reasoning breakdown
                st.markdown("### ğŸ§  AI Reasoning")
                st.info(recommendation.reasoning)
                
                # What happens next
                if recommendation.decision != RLDecision.SKIP:
                    st.success(f"""
                    âœ… **Auto-RL will trigger** when this task is executed!
                    
                    - Training will start automatically after task completion
                    - No user intervention required
                    - Results will be tracked and optimized
                    """)
                else:
                    st.warning("âšª Auto-RL will skip this task (not beneficial for RL training)")
    
    def create_performance_dashboard(self):
        """Create performance tracking dashboard"""
        
        st.subheader("ğŸ“ˆ RL Performance Analytics")
        
        # Generate mock performance data
        dates = pd.date_range(start=datetime.now() - timedelta(days=30), end=datetime.now(), freq='D')
        
        performance_df = pd.DataFrame({
            'date': dates,
            'task_completion_rate': np.random.normal(85, 5, len(dates)),
            'rl_sessions': np.random.poisson(3, len(dates)),
            'agent_efficiency': np.random.normal(78, 8, len(dates)),
            'learning_improvement': np.cumsum(np.random.normal(0.1, 0.5, len(dates)))
        })
        
        # Performance metrics over time
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            x=performance_df['date'],
            y=performance_df['task_completion_rate'],
            mode='lines+markers',
            name='Task Completion Rate (%)',
            line=dict(color='#1f77b4', width=3)
        ))
        
        fig.add_trace(go.Scatter(
            x=performance_df['date'],
            y=performance_df['agent_efficiency'],
            mode='lines+markers',
            name='Agent Efficiency (%)',
            line=dict(color='#ff7f0e', width=3),
            yaxis='y2'
        ))
        
        fig.update_layout(
            title='Agent Performance Trends (30 Days)',
            xaxis_title='Date',
            yaxis_title='Completion Rate (%)',
            yaxis2=dict(
                title='Efficiency (%)',
                overlaying='y',
                side='right'
            ),
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # RL Impact Analysis
        col1, col2 = st.columns(2)
        
        with col1:
            # RL Sessions Distribution
            rl_dist = pd.DataFrame({
                'Decision': ['Skip', 'Light', 'Standard', 'Intensive'],
                'Count': [45, 25, 20, 10],
                'Color': ['#ff4444', '#ffaa44', '#44aaff', '#44ff44']
            })
            
            fig_pie = px.pie(
                rl_dist, 
                values='Count', 
                names='Decision',
                title='RL Decision Distribution',
                color_discrete_sequence=rl_dist['Color']
            )
            st.plotly_chart(fig_pie, use_container_width=True)
        
        with col2:
            # Agent RL Usage
            agent_rl = pd.DataFrame({
                'Agent': ['Data Scientist', 'Full Stack', 'DevOps', 'Architect', 'Security'],
                'RL_Sessions': [15, 12, 8, 6, 4],
                'Improvement': [23.5, 18.2, 15.1, 12.8, 9.3]
            })
            
            fig_bar = px.bar(
                agent_rl,
                x='Agent',
                y='RL_Sessions',
                title='RL Usage by Agent Type',
                color='Improvement',
                color_continuous_scale='Viridis'
            )
            st.plotly_chart(fig_bar, use_container_width=True)
    
    def create_smart_controls(self):
        """Create intelligent RL control panel"""
        
        st.subheader("âš™ï¸ Smart RL Controls")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ›ï¸ Auto-RL Settings")
            
            # RL Sensitivity
            sensitivity = st.slider(
                "RL Trigger Sensitivity",
                min_value=0.1,
                max_value=2.0,
                value=1.0,
                step=0.1,
                help="Higher = more aggressive RL training"
            )
            
            # Performance threshold
            perf_threshold = st.slider(
                "Performance Threshold",
                min_value=50,
                max_value=95,
                value=75,
                help="Minimum performance before RL kicks in"
            )
            
            # Max concurrent RL sessions
            max_sessions = st.number_input(
                "Max Concurrent RL Sessions",
                min_value=1,
                max_value=10,
                value=3,
                help="Limit parallel RL training"
            )
        
        with col2:
            st.markdown("### ğŸš€ Quick Actions")
            
            if st.button("ğŸ”„ Refresh RL Models", type="secondary"):
                st.success("RL models refreshed successfully!")
            
            if st.button("ğŸ“Š Generate RL Report", type="secondary"):
                st.success("Comprehensive RL report generated!")
            
            if st.button("ğŸ§¹ Clean RL Cache", type="secondary"):
                st.success("RL cache cleaned!")
            
            # Emergency controls
            st.markdown("### ğŸš¨ Emergency Controls")
            
            col_a, col_b = st.columns(2)
            with col_a:
                if st.button("â¸ï¸ Pause Auto-RL", type="secondary"):
                    st.warning("Auto-RL paused!")
            
            with col_b:
                if st.button("ğŸ›‘ Stop All RL", type="secondary"):
                    st.error("All RL training stopped!")
    
    def create_live_monitoring(self):
        """Create live RL monitoring"""
        
        st.subheader("ğŸ“¡ Live RL Monitoring")
        
        # Real-time status
        status_container = st.container()
        
        with status_container:
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown("""
                ### ğŸŸ¢ Active Sessions
                - **PPO Training**: Agent #1 (Epoch 3/5)
                - **DQN Optimization**: Agent #2 (Epoch 7/10)
                """)
            
            with col2:
                st.markdown("""
                ### ğŸ“Š Queue Status
                - **Pending**: 2 tasks
                - **Processing**: 1 task  
                - **Completed**: 15 tasks
                """)
            
            with col3:
                st.markdown("""
                ### âš¡ System Health
                - **CPU**: 45% (Normal)
                - **Memory**: 62% (Normal)
                - **GPU**: 78% (High)
                """)
        
        # Live logs
        st.markdown("### ğŸ“ Live RL Logs")
        
        log_container = st.container()
        with log_container:
            logs = [
                "ğŸŸ¢ [14:23:45] Auto-RL triggered for optimization task (confidence: 87%)",
                "ğŸ”µ [14:23:42] PPO training started - Agent: data_scientist",
                "âšª [14:23:38] Task analyzed - RL decision: skip (simple task)",
                "ğŸŸ¡ [14:23:35] Light RL training completed - 2 epochs",
                "ğŸŸ¢ [14:23:30] Performance improvement detected: +15.3%"
            ]
            
            for log in logs:
                st.text(log)

def main():
    st.set_page_config(
        page_title="Smart RL Dashboard",
        page_icon="ğŸ§ ",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("ğŸ§  Smart RL Training Dashboard")
    st.markdown("**Intelligent Reinforcement Learning Management System**")
    
    dashboard = SmartRLDashboard()
    
    # Sidebar navigation
    with st.sidebar:
        st.header("ğŸ›ï¸ Navigation")
        
        page = st.radio(
            "Select View:",
            [
                "ğŸ  Overview",
                "ğŸ¯ Task Analyzer", 
                "ğŸ“ˆ Performance",
                "âš™ï¸ Controls",
                "ğŸ“¡ Live Monitor"
            ]
        )
        
        st.markdown("---")
        st.markdown("### ğŸ“Š Quick Stats")
        st.metric("RL Enabled", "âœ… Yes")
        st.metric("Auto Mode", "ğŸŸ¢ Active")
        st.metric("Success Rate", "94.2%")
    
    # Main content based on selection
    if "Overview" in page:
        dashboard.create_rl_intelligence_panel()
        dashboard.create_task_analyzer()
    
    elif "Task Analyzer" in page:
        dashboard.create_task_analyzer()
    
    elif "Performance" in page:
        dashboard.create_performance_dashboard()
    
    elif "Controls" in page:
        dashboard.create_smart_controls()
    
    elif "Live Monitor" in page:
        dashboard.create_live_monitoring()
    
    # Footer
    st.markdown("---")
    st.markdown("ğŸš€ **Auto-RL System**: Intelligently optimizing agent performance without user intervention")

if __name__ == "__main__":
    main()